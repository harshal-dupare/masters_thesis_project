\chapter{Related Works}
% Write about the literature that you have studied regarding the work that you have carried out for the project\\
% Have introduction describig the different aspects of the problem and what all type of literature can be similar to it eg. MOOP solution methods, computing conditional number\\
\hspace{1cm}Before we look for the related works to this problems it is important to understand the different dimensions of this problem and structure the related works accordingly. The problems stated in the section \ref{prob_def} has 1 major characteristic apart from being fMOOP is that it requires the solution to have bounded condition number (absolute or relative), and on top of that since such formulation has many applications it is desirable to have efficient algorithms to compute such solutions. So the following dimensions of the literate that interests us and can have impact of the problem are:
\begin{enumerate}
    \item Methods to solve MOOP \label{lit_dim_1}
    \item Literature related to condition number \label{lit_dim_2}
    \item Efficiency in the computational aspects of both \ref{lit_dim_1}, and \ref{lit_dim_2}
\end{enumerate}
As we will see that lot of research has been done in solving MOOP and we have fairly efficient methods to get the solutions. But when it comes to the implications of condition number most of the research is focused on the condition number of matrices compared to that of condition number of general functions.
% Have main body which summarizes all the literature and their results, generally for different aspects of the problem write a summary by theme and then by methedology.\\
% Connect the dots with regularizations using scalarization//

% In this chapter, we will review some of the related literature. Several datasets have been collected from various social media platforms such as Twitter, Facebook, Reddit ,etc for hate-speech detection. Largely the focus has been remained on identifying the hate-labeled post by identification of hate-keywords and then taking the necessary action against the user by either suspending his account or removing his posts.There has been some concern about this action because it could trigger an escalation of the discussion about what constitutes hate speech and what is not. Therefore we try to look at both the ends of the pipeline through reviewing the literature for detoxifying the online media through hate-detection systems and deploying generative models for counter-narratives generation.    
\newpage
\section{Multi-Objective Optimization}
\subsection{Definitions}
In MOOP since there are more than one objectives its unlikely that all of them achieve their optima at the same point, hence typically there is no single global solution. Which makes its necessary to rethink about the definition for an optimum and accordingly determine a set of points that can be deemed as the solutions. The most widely used concept concept in defining an optimal point is that of the \textit{Pareto optimality} \cite{pareto1971manual}, which is defined as follows:\newline 
Below we will use $F: X \to \mathbb{R}^k$ as the objective function that we need to minimize over the input $x\in X$ and we will use minimization over all the objectives since maximization can be converted to minimization by negating the sign.\newline\newline
\textbf{Pareto Optimal}: A point, $x^{*} \in X$, is
Pareto optimal iff there does not exist another point, $x \in X$, such that $F(x) \le F(x^{∗})$, and $F_i(x)<F_i(x^{∗})$ for at least one function. 
\newline\newline
All Pareto optimal points lie on the boundary of the feasible criterion space \cite{Athan1996-cm}. Sometimes the pareto optamility is too strong of a requirement hence we define \textit{weakly Pareto optimal} as follows:\newline\newline
\textbf{Weakly Pareto Optimal}: A point, $x^{*} \in X$, is weakly Pareto optimal iff there does not exist another point, $x \in X$, such that $F(x) < F(x^{∗})$.\newline\newline
Pareto optimal points are weakly Pareto optimal, but weakly Pareto optimal points are not Pareto optimal.\newline
Alternatively we define the compromise solution, which minimizes the difference between the utopia point/ideal point, defined as follows \cite{vincent1981optimality}:\newline\newline
\textbf{Utopia Point} \label{ideal_point_def}: A point $F^{*} \in \mathbb{R}^k$ is objective space, is a utopia point iff for each $i = 1, 2 ... ,k$, $F^{*}_i = \underset{x \in X}{min} \{ F_i(x)|x \in X\}$.\newline\newline
In general, $F^{*}$ is infeasible due to other constrains. Then the next best solution that we can attain is a solution that is as close as possible to the utopia point. We call such solution a \textbf{compromise solution} and it is Pareto optimal. The meaning of close in this context needs to be clarified and generally we need to define norms to measure closeness of the solutions for example use of Euclidean norm \cite{vincent1983game}. Another problem with this approach is of different objective have different scales so generally we need to transform the objectives to a single scale for any meaningful use of the defined norm.

The methods to solve MOOP are classified into 4 classes \cite{hwang2012multiple} based on the availability and involvement of a external decision maker(\textit{DM}) used to convey the preference over different pareto optimal solution.
\begin{enumerate}
    \item \textbf{No preference methods}: No \textit{DM} is available and a neutral compromise solution is identified without any specification of the preference information.
    \item \textbf{A priori methods}: based on the preference information given by the \textit{DM} the optimal solution is found.
    \item \textbf{A posteriori methods}: a good representative set of Pareto optimal solutions is found, and from among them the \textit{DM} must choose the best solution.
    \item \textbf{Interactive methods}: Pareto optimal solution(s) are shown to the \textit{DM}, then the \textit{DM} describes how the solution(s) could be improved. Then the next set of Pareto optimal solution(s) is generated based on the \textit{DM}'s feedback and iteratively the solutions are improved.
\end{enumerate}

\subsection{No Preference Methods}
Since no preference information is provided the general one the approaches followed in \cite{zeleny1973compromise} uses the definition of \textbf{utopia point} in \ref{ideal_point_def} and then by properly scaling the objective function $F$ to $\hat{F}$ and using a $||\cdot||$ norm defined over the objective space the following optimizations problem is formulated to minimize the following objective.
\begin{equation}
    \underset{x \in X}{min}\hspace{1mm} ||\hat{F}(x) - \hat{F}^{*}||
\end{equation}
\newline Other similar methods are described in \cite{miettinen1998}.

\subsection{A Priori Methods}
Methods which come under this class can further divided into other smaller classes but all of them have a common feature that is,enough information is provided a priori to compare any candidate pareto optimal solutions.
\newline Following are some of the Important methods under this class:
\newline \newline \textbf{Utility Function Methods}: Here we have a utility function $U: \mathbb{R}^k \to \mathbb{R}$, and the goal is to solve the following SOOP
\begin{equation}
    \underset{x \in X}{min}\hspace{1mm} U(F(x))
\end{equation}
\newline Notable methods which come under this utility model are
\begin{equation} \label{lin_utility_model}
    U(F(x)) = \mathlarger{\mathlarger{\sum}}_{\forall i\in [k]} w_i F_i(x)
\end{equation}
\newline Known as the Linear scalarization method, if all $\forall i \in [k], w_i > 0$ is a sufficient condition for the solution of \ref{lin_utility_model} to be a pareto optima \cite{zadeh1963optimality}, but it is not a necessary condition \cite{zionts1989multiple}.
\begin{equation} \label{eq11}
    U(F(x)) = \mathlarger{\mathlarger{( \sum}}_{\forall i\in [k]} w_i (F_i(x)-F^{*}_i)^p \mathlarger{\mathlarger{) }}^{1/p}
\end{equation}
\newline \ref{eq11} for $p>0$,generally $p=1,2$ is another common extension of the formulation \cite{yu1976compromise}, for pareto optamility the conditions on $w_i$ are same as they are for \ref{lin_utility_model}, along with that if any of the $w_i$ is set to $0$ then it can result in weak pareto optimality.
\begin{equation} \label{HypervolumeChebyshevScalarization}
    U(F(x)) = \underset{i\in [k]}{max}\hspace{1mm} \frac{F_i(x)}{w_i}
\end{equation}
\newline \ref{HypervolumeChebyshevScalarization} is known as Hypervolume/Chebyshev Scalarization method \cite{zhang2020random}, and in this case if $\forall i \in [k] \hspace{1mm} w_i>0$, it is shown that the solution of \ref{HypervolumeChebyshevScalarization} converges to the Pareto front even for non-convex pareto fronts.
\newline \newline \textbf{$\epsilon$-Constraint Method}:
In this method\cite{haimes1971bicriterion} we have a single most important objective function $F_s(x)$. and the remaining objective functions are used to form additional constraints $F_i(x) \le \epsilon_i,\forall i \in [k]/\{s\}$.

\begin{equation}\label{eps_const_obj}
    \underset{x \in X}{min}\hspace{1mm} F_s(x)
\end{equation}
\newline subject to the constraints
\begin{equation}\label{eps_const_con}
    F_i(x) \le \epsilon_i,\hspace{2mm} \forall i \in [k]/\{s\}
\end{equation}\newline
It is proven that the by a systematic variation of $\epsilon_i$ one can generate a set of Pareto optimal solutions\cite{hwang1979methods}.
If the solution of \ref{eps_const_obj},\ref{eps_const_con} exists then it is a weakly Pareto optimal solution \cite{miettinen2012nonlinear}, and if the solution is unique, then it is Pareto optimal \cite{miettinen2012nonlinear}.
\newline \newline \textbf{Lexicographic Method}: As the name suggests, the Objective functions are ordered as per decreasing order of importance namely $F_i(x)$ is more important than $F_j(x)$ iff $i<j$. Then, the following optimization problems are solved starting from $i=1,2,...,k$.
\begin{equation} \label{lex_obj}
    \underset{x\in X}{min}\hspace{1mm} F_i(x)
\end{equation}
\newline subject to
\begin{equation} \label{lex_constraints}
    F_j(x) \le F_j(x^{*}_j), \forall j \in \{1,2,...i-1\}\hspace{2mm}
\end{equation}
\newline In \ref{lex_constraints} we can also have $=$ instead of $\le$, \cite{stadler1988multicriteria}. Here $x^{*}_j$ is the solution obtained at the $j$'th iteration, initially for $i=j=1$ there are no constrains and $F_i(x)$ is minimized over $x\in X$. 
\newline \newline \textbf{Goal Programming Methods}: Goal Programming method was developed by \cite{charnes1955optimal}, \cite{ijiri1965management}, \cite{charnes1967effective}. In this method we have been given goals $g_j$ which are expected by the \textit{DM} for the objective $F_j(x)$ respectively. To measure the deviations from the goal the sum of the absolute deviation is minimized. 
\begin{equation}
    \underset{x\in X}{min} \hspace{1mm}\mathlarger{\mathlarger{\sum}}_{\forall i\in [k]} |g_i - F_i(x)|
\end{equation}
\subsection{A Posteriori Methods} \label{a_posteriori_method}
As the name suggest that the \textit{DM} is involved a posteriori of finding solution, these apprpaches are also known as generate-first-choose-later approaches \cite{messac2002generating}. The goal is to produce a good enough representative subset of solutions which are Pareto optimal. In general they are classified into 2 classes.

\begin{enumerate}
    \item \textbf{Mathematical programming methods}, which generally work by producing 1 pareto optimal solution per iteration/run of the algorithm.
    \item \textbf{Evolutionary algorithms}, which produce a set of Pareto optimal solutions per iteration/run of the algorithm.
\end{enumerate}

\subsubsection{Mathematical Programming Methods}
Few of the well known methods in this class are:
\begin{enumerate}
    \item Normal Boundary Intersection Method
    \item Modified Normal Boundary Intersection Method
    \item Normal Constraint Method
\end{enumerate} 
\textbf{Normal Boundary Intersection Method (NBI)}: \label{nbi_method_def}
As discussed the section \label{lin_utility_model} the weighted sum method does provide a pareto optimal solution but its is very difficult to find evenly spread solution by varying the weights, to address these and other computational drawbacks Das and Dennis in their paper \textit{Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems} \cite{das1998normal} presented the NBI method, whichis formulated as follows:
\begin{equation} \label{nbi_obj}
    \underset{x\in X, t}{min} \hspace{1mm} t
\end{equation}
\begin{equation}
    \Phi w + t \mu = F(x) - F^{*}
\end{equation}
Where $\Phi \in \mathbb{R}^{k\times k}$ is the pay-off matrix whose $\Phi_{ij}$ entry measures the difference in the optimal value for $j$'th objective considering only the $i$'th objective to be minimized and that of the utopia point \ref{ideal_point_def}, i.e. $\Phi_{ij} = F_j(\underset{x\in X}{argmin}\hspace{1mm} F_i(x))-F^{*}_j$ . Also $\mu = - \Phi e$, $\mu$ is known as the quasi-normal vector and $e^{\top}w=\sum_{i\in [k]} w_i = 1$ which is provided by the user. NBI method doesn't provide sufficient condition for finding pareto optimal solutions hence it is possible that the solutions obtained via this method are not pareto optimal and neither does this provide a necessary condition for pareto optimal solutions since for $k>2$ for some problems it overlooks some of the pareto optimal solutions.
\newline\newline \textbf{Modified Normal Boundary Intersection Method (NBIm)}: \label{nbim_method_def} As stated in \ref{nbi_method_def} the NBI method suffers from not even being a necessary condition for pareto optimal solutions, Das \cite{das1999improved} and R de S Motta \cite{de2012modified} proposed modified methods to cover these drawbacks
\newline\newline \textbf{Normal Constraint Method (NC)}: \label{nc_method_def} Messac et al. \cite{messac2003normalized} \cite{messac2004normal} proposed the NC method an alternative to NBI method, which provided some improvements. It uses the utopia point \ref{ideal_point_def} to normalize the objective vector $F(x)$ to $\hat{F}(x)$ along with a pareto filter which removes the non-dominant solutions to keep only the dominant solutions.Also it always produces pareto optimal solutions along with it's performance being independent of design objective scales. 

\subsubsection{Evolutionary Algorithms (EA)}
Evolutionary algorithms are one of the very actively researched methods \cite{vikhar2016evolutionary} for solving MOOP and finding pareto optimal solutions. EA are subset of the paradigm which is inspired by nature and evolution in designing algorithms for various purposes including solving optimization problems. The general procedure that and EA follows is described below:
\begin{algorithm}
\caption{Generic EA}\label{algo_generic_ea}
\begin{algorithmic}
\Function{EA}{$\mathcal{I}$} \Comment{gets input parameters $\mathcal{I}$}
    \State $\mathcal{P} \gets initialize(\mathcal{I})$ \Comment{initialize solution population $\mathcal{P}$}
    \While{$converges(\mathcal{P}) \lor terminate(\mathcal{P})$} \Comment{till convergence or termination}
        \State $\mathcal{P} \gets evolve(\mathcal{P},\mathcal{I})$ \Comment{evolve the population to next generation}
    \EndWhile
    \Return $\mathcal{P}$
\EndFunction
\end{algorithmic}
\end{algorithm}\newline Some of the notable methods in EA which are commonly used are:
\begin{enumerate}
    \item Non-dominated Sorting Genetic Algorithm-II (NSGA-II)
    \item Ant Colony Optimization (ACO)
    \item Particle swarm optimization (PSO)
\end{enumerate} 
\textbf{Non-dominated Sorting Genetic Algorithm-II (NSGA-II)}: \label{nsga_2} Proposed by K. Deb et al. in the paper \textit{A Fast and Elitist Multi-objective Genetic Algorithm: NSGA-II} \cite{deb2002fast}, NSGA-II is based on elitist principle meaning only the elites of the populations survive to the next generation based on a partial-order sorting of the population, to decide the elites.
\newline\newline \textbf{Ant Colony Optimization (ACO)}: \label{ant_colony_opt} it is based on idea of ant pheromone which ants use to communicate to form paths and explore more of the promising regions \cite{slowik2017nature}.
\newline\newline \textbf{Particle Swarm Optimization (PSO)}: \label{partical_swarm_opt} PSO is based on the flocking behaviour of the birds where each particle has a position (the solution) and a velocity (change in the solution) where the velocity is influenced by some neighbourhood of the particle \cite{poli2007particle}.
\newline\newline The advantage the EA provides is that it can quickly provide a sets of solutions which even though are not guaranteed to be pareto optimal, but are non-dominant set and serve as good approximation to the entirety of the Pareto front. The disadvantages being that these algorithms are relatively slow and pareto optimality cant be guaranteed.

\subsection{Interactive methods}
Interactive methods require the \textit{DM} to actively take part in pruning the candidates solutions suggested by the method, and based on the input of the \textit{DM} the method adopts and suggest new solutions which are then again evaluated by the \textit{DM} and the process is repeated to improve and adopt the solutions as per the needs of \textit{DM}.
\newline\newline The generic structure of the Interactive methods is as follows \cite{miettinen2008introduction}:
\begin{algorithm}
\caption{Generic Interactive Method}\label{algo_generic_interactive_method}
\begin{algorithmic}
\State $\mathcal{P} \gets initialize(\mathcal{M})$ \Comment{pareto optimal solution set: $\mathcal{P}$; no-preference method: $\mathcal{M}$}
\Do
    \State $\mathcal{R} \gets getPreference(\mathcal{P},DM)$\Comment{preference information: $\mathcal{R}$, decision maker: $DM$ }
    \State $\mathcal{P} \gets newSolutionSet(\mathcal{P},\mathcal{R})$\Comment{update solution set based on $\mathcal{R}$}
\doWhile{$converges(\mathcal{P},DM) \lor terminate(\mathcal{P},DM)$}\Comment{till convergence or termination}
\end{algorithmic}
\end{algorithm}
The above method can be classified based on the which method is used as $\mathcal{M}$ and what type of preference information $\mathcal{R}$ is available/provided by the \textit{DM}.
\newline \newline $\mathcal{M}$ can be chosen from the various options available in a posteriori methods/no preference method \ref{a_posteriori_method} based on the problem type.
\newline \newline Generally the choices of $\mathcal{R}$ are classified into 3 classes \cite{miettinen2008introduction}.
\begin{enumerate}
    \item \textbf{Trade-off Between Objectives}: Here the \textit{DM} is shown various trade-off scenarios and asked their preference in regards to those trade-off, and based on that the next solution set is generated \cite{zionts1976interactive}.
    \item \textbf{Reference Point}: Here the \textit{DM} for a get set of $\mathcal{P}$ pareto optimal solutions needs to provide a reference point w.r.t. which the next iteration will generate the updated solution set  $\mathcal{P}$ \cite{wierzbicki1986completeness}, \cite{wierzbicki2000modern}.
    \item \textbf{Classification of Objectives}: Here for a given $\mathcal{P}$ the \textit{DM} classifies different objectives of the solutions such as to get more preferred solutions, and based on the classification the updates solution set $\mathcal{P}$ is generated.
\end{enumerate}
\newpage
\section{Condition Number}
The term \textbf{\textit{Condition Number}} was first coined by Alan Turing in 1947 in his paper on Rounding-Off Errors in Matrix Processes \cite{turing1948rounding}. He defined the condition number for matrices, further in 1966, John Rice in his paper \textit{A Theory of Condition} \cite{rice1966theory} showed how to formulate the definition of condition number other classes of problems.
\newline\newline In our problem formulation may we not only require to compute the condition number of the function $f$ to check if its bounded or not \ref{cond_abs},\ref{cond_rel}; but also to minimize the maximum over a set $X_3$ \ref{cond_abs_min},\ref{cond_rel_min}.
\newline\newline Hence we need to methods which can either be used to 
\begin{enumerate}
    \item Bound the relative/absolute condition number
    \item Compute relative/absolute condition number efficiently
\end{enumerate}
Extensive amount of literature is available on condition number of matrices compared to that of general functions. Below we will see some results on condition number of matrix and also for general function.
\subsection{Condition Number of Matrices}
There are several papers which have proved various important properties of matrix condition number. Pierre Maréchal and Jane J. Ye in their paper \textit{Optimizing Condition Numbers}\cite{marechal2009optimizing} showed that for a symmetric positive semi-definite $n\times n$ matrix $A$ minimizing the condition number $\kappa (A)$.
\begin{equation} \label{cond_matrix}
    \kappa (A) = ||A||||A^{-1}||
\end{equation}
\begin{equation} \label{min_cond_matrix}
    \underset{A}{min}\hspace{1mm} \kappa (A)
\end{equation}
\ref{min_cond_matrix} is euqivalent to minimizing the following objective
\begin{equation}
    \underset{A}{min}\hspace{1mm} \lambda_1(A) - \kappa (\Bar{A}) \lambda_n(A)
\end{equation}
where $\Bar{A}$ is the optimal solution with minimum condition number, if such a solution's value of $\kappa (\Bar{A})$ is not known, then one can use a desirable value of $\kappa (\Bar{A})$ in its place. Here $\lambda_i(A)$ are the eigenvalues of the matrix $A$ in decreasing order of their magnitude form $i=1,2,...,n$. They also proved that that the problem of minimizing the condition number is non-smooth and non-convex optimization problem \cite{marechal2009optimizing}, which further increases the difficulty of the problem. In their paper \textit{Convexity Properties of the Condition Number } \cite{beltran2010convexity}, C Beltrán et al. have studied the convexity properties of the condition number over norm over frobenius inner product. Further Xiaojun Chen et al. in their paper \textit{Minimizing the Condition Number of a Gram Matrix} \cite{chen2011minimizing} analysed the same for $A$ being a gram matrix of functions of a scalar $x$, namely $A(x) = V(x)^{\top}V(x)$ and derived formulas for generalized gradient of $\kappa(A(x))$, and using exponential smoothing function they also develop a globally convergent smoothing method to solve the \ref{min_cond_matrix} problem.


\subsection{Condition Number of Functions}

%which was evaluated using bystander interactions. 
% \textbf{\cite{qian2019benchmark}} have released a Dataset to intervene in Online Hate Speech which consists of conversation-segments,hate-speech labels, as well as intervention responses, written by Mechanical Turk Workers. This data was retrieved from Reddit using the most toxic subreddits. Some of the subreddits were: r/DankMemes, r/Imgoingtohellforthis, r/PussyPassDenied etc,. A similar data retrieval technique was used for Gab. Around 3847 responses were labelled as hatespeech in case of Reddit and a total of 11169 responses were labelled as hatespeech for Gab.

% \par
% \textbf{\cite{CONAN}} created the first large-scale, multilingual, expert-based dataset with an effort of more than 100 operators from three different NGOs thus providing varied range of intervention responses. The hate-counterspeech pairs were collected through nichesourcing to three different NGOs from UK, Italy and France We only took the English corpus for our study. 

% \par
% \textbf{\cite{mathew2019thou}} annotated and released the first ever dataset on counter-speech. The dataset is based on counterspeech targeted to mainly three communities which are Blacks,Jews and LGBT.
% It comprises of 6898 comments annotated as counterspeech and an additional 7026 comments tagged as non-counter-speech.

% \par They have categorized the counterspeech into the following types:
% \begin{enumerate}
%     \item \textbf{Presenting facts to correct misconceptions : }For example a counter-narrative to hate-speech against LGBTQ community would be "Actuallly homosexuality is natural and nearly all known species have their gay commonalities."
%     \item \textbf{Pointing out contradictions in the arguement : }
%     The counterspeaker uses this tactic to point out the user's (hate) statements' contradictions or inconsistency. "Christians only follow the parts of bible that supports their bigotry which prove that they are hypocrites."
%     \item \textbf{Warning of consequences : }
%     "You could be arrested for supporting child abuse. Be careful"-is a type of counterspeech in which the user warns the person of dire consequences.
%     \newpage
%     \item \textbf{Showing Affiliation : }Establishing, sustaining, or restoring a positive affective relationship with another individual or group of people is referred to as affiliation.
%     \item \textbf{Denouncing hateful or dangerous speech : }Most of the intervention responses provided in the Gab and Reddit dataset belong to this category. An example of this category could be - "Use of re---ded is disrespectful and you should avoid using that".
%     \item \textbf{Humor and sarcasm : }One of the most effective methods used by counterspeakers to fight hate speech is humour.
%     \item \textbf{Positive Tone : } We consider different types of speech in this approach, such as empathic, kind, respectful, or civil.
%     \item \textbf{Using Hostile Language : }This is 
%     another category of counter-speech in which the user responds with more hate in response to hate-speech. We have omitted these examples for our experiments.
% \end{enumerate}

% \begin{table}[h]
% \begin{tabular}{|p{5cm}||p{5cm}|p{5cm}|}
%  \hline
%  \textbf{Dataset} & \textbf{Target commumity} & \textbf{Total data(rows)} \\
%  \hline
%   CONAN   &  Muslims(Islam) &  \textbf{3864(EN)} \\
%  \hline
%   Reddit & Mixed(Hate/Non-Hate) & \textbf{3847} \\
%  \hline 
%   GAB & Mixed(Hate/Non-Hate) & \textbf{11169}\\
%  \hline 
%   ICWSM & Counter/Non-counter & \textbf{6898}\\
%   \hline
% \end{tabular}
% \caption{Data-Stats used in the experriment}
% \label{Data_Stats}
% \end{table}

% \section{PreTrained Language Models}
% In this section, we would discuss the basics of natural language generation using pre-trained language models. In addition, we would describe the approaches that can be applied to natural language generation in more complex applications and a brief explanation of the gpt2 architecture. We then further explore the Plug and Play Language Models(PPLM) which allow a user to flexibly plug in one or more simple attribute models representing the desired control objective into a large, unconditional Language-Model.
% \newpage
% We then review the PPLM models with different attribute settings and provide an overview of how to best utilize their properties to generate counter-speech.

% \subsection{Casual Language Modeling}
% A dialogue consists of a sequence of interactions among participants. We define the conversation sequence as turn of dialogues as $D_t$ and $R_{t}$ = \{$d_{1},r_{1},d_{2},r_{2}, \ldots, d_{t}$\} where $d_{t}$ is the user input and $r_{t}$ is the generated response. Upon concatenation of $D_{t}$ and $R_{t}$ as the sequences of tokens 
% $X$ = \{$x_{0},x_{1},...,x_{i-1}$\}, then by chain rule of probability, the language model distribution can be computed as :

% \[
%     p(X) = \prod_{i=1}^{n}p(x_{i}\big|x_{0},\ldots,x_{i-1})
% \]

% Here we use the a transformer based language model- GPT2 \cite{radford2019language} which generates tokens in an auto-regressive manner. 

% \par The basic architecture of the transformers is shown in Figure \ref{fig:Transformer_architecture}.

% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.8\linewidth]{Graphics/transform_ct.png}
%     \caption{Encoder-Decoder Architecture of a Transformer}
%     \label{fig:Transformer_architecture}
% \end{figure}
% % \newpage
% \par GPT-2 is a decoder-only transformer and following the satndard notation, we define the transformer decoding process in a recursive manner. The matrix $H_{t}$ is defined as key-value pairs from the past dialogue history, i.e., $H_{t}= \big[\left(K_{t}^{(1)},V_{t}^{(1)}\right),\ldots,\left(K_{t}^{(l)},V_{t}^{(l)}\right)\big]$ , where $\left(K_{t}^{(i)},V_{t}^{(i}\right)$ represents the key-value pairs generated at all time-steps $t\in\left[0,t\right]$. 

% \par Then the decoding process can be called as:
% \[ 
%         o_{t+1},H_{t+1} = LM(x_{t},H_{t})
% \]
% and then next token $x_{t+1}$ is sampled from distribution $p_{t+1} = Softmax(W_{o_{t+1}})$, where $W$ matrix is the linear transformation, which maps the last layer to vocabulary size.
% % \newpage
% We have used the GPT2 and the DialoGPT(\cite{zhang2019dialogpt}) for fine-tuning and carrying out the experiments. DialoGPT is a GPT-2 based model trained on a Reddit corpus of dialogues collected over a period of 10 years.


% \subsection{Controlled Text-Generation using Plug and Play Models(PPLMs)}
% Researchers worldwide have shown that unprecedented fluency can be demonstrated in training language models on large corpus. By considering a variety of different domains and topics, either from scratch or when given a prefix by the user, Language Models can generate coherent sentences. 
% \par Although these gigantic language models have exceptional generation capabilities, it is difficult to steer them in the direction of a specific feeling, which means that many possible phrases can be generated or the generated sentences don't necessarily follow a particular pattern or exhibit similar characteristics. 

% \begin{figure}[h]
%     \centering
%     \includegraphics[scale=0.5,width=0.8\linewidth]{Graphics/mammoth.png}
%     \caption{The attribute model roughly 100,000 times smaller than the unconditional Language Model steering it to possess a desired sentiment}
%     \label{fig:giant_mammoth}
% \end{figure}


% \par The Plug and Play Model(PPLM)\cite{dathathri2020plug} allows a user to plug in one or more attribute models representing the desired control sentiment into a large unconditioned Language Model. 

% \newpage

% \par This method requires no fine-tuning and thus solves the problem of requirement of humongous architecture for training and it also eliminates the possibility of catastrophic forgetting.


% \par PPLM lets users combine smaller attribute models as shown in \ref{fig:giant_mammoth} with an LM to steer its generation where attribute models can be relatively much smaller than the Language Model.
% \newpage
% \vspace{5cm}
% \par We denote the unconditional model LM by $p(x)$, which is a probability distribution over complete text. This is modeled by the original unconditional LMs like GPT2 and secondly there is the required probability distribution $p(x|a)$ which is the conditional LM. The attribute model represented by $p(a|x)$, outputs the probability of $x$ possessing the attribute $a$ and the second distribution can be expressed in the terms of the first and second distribution using Bayes' Rule given by:
% \[
%     p(x|a) \propto p(a|x)p(x)
% \]


% \begin{figure}[h]
%     \centering
%     \includegraphics[width=0.8\linewidth]{Graphics/PPLM_imag.png}
%     \caption{The PPLM generation approach decomposed into three steps}
%     \label{fig:Transformer_achitecture}
% \end{figure}

% \par The PPLM agorithm entails three simple steps to generate a sample:
% \begin{enumerate}
%     \item Given a partially generated sentence, $log(p(x))$ and $log(p(a|x))$ and the gradients of each with respect to the hidden representation of the underlying language model is computed.
%     \item Then Use the gradients to move the hidden representation of the language model a small step in the direction of increasing $log(p(x))$ and $log(p(a|x))$.
%     \item Sample the next word.
% \end{enumerate}


% \par The attribute models could either be one of the following or the combination of the both:
% \newpage
% \begin{enumerate}

%     \item The simplest attribute model $p(a|x)$ is a Bag-of-Words(BOW) model representing a sentiment, where the likelihood is given by the sum of likelihoods of each word in the bag. A Bag-of-words representing the topic space may contain very specific words such as "galaxy","star","sun","space" and "planets" among others. The generation sample is shown in \ref{fig:BOWWORDS}.

% \begin{figure}[h]
%     \centering
%     \includegraphics[scale=0.4,width=0.8\linewidth]{Graphics/BOW_SAMPLE.png}
%     \caption{The PPLM-BOW samples corresponding to different topics and the original GPT2 sampling in the top row.}
%     \label{fig:BOWWORDS}
% \end{figure}

%     \item A discriminator trained on a dataset labelled with the desired attributes could be the second attribute model to represent a subject attribute. A single layer classifier attribute model is deployed by models of this type denoted by PPLM-Discrim that predict the target label from the mean of the embedded representation extracted from the original unconditioned language model. The generation sample is shown in \ref{fig:BOWDISCRIM}.

% \end{enumerate}
% % \newpage
% \begin{figure}[h]
%     \centering
%     \includegraphics[scale=0.4,width=0.8\linewidth]{Graphics/PPLM_DISCRIM_SAMPLE.png}
%     \caption{The PPLM-Discrim steering the samples corresponding to positive and negative sentiment.}
%     \label{fig:BOWDISCRIM}
% \end{figure}

