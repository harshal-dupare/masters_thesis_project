{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "JAd6GQzOfYzu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdtxvgcVeovm",
        "outputId": "cd8aa5ea-0633-4b26-cbfb-d3237f3f4c01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/mtp-thesis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MZw_zKEfykK",
        "outputId": "9089bef0-aed4-4283-884b-d907d8f21927"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mtp-thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "YjTVLUcggKy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FILE = '/content/drive/MyDrive/mtp-thesis/data/X_train_YG7NZSq.csv'"
      ],
      "metadata": {
        "id": "OPKcxEOVgNQb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS_FOLDER = '/content/drive/MyDrive/mtp-thesis/results'"
      ],
      "metadata": {
        "id": "Rzi4e_vjTXdw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "I4T5E9mSggMN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_data = pd.read_csv(DATA_FILE)\n",
        "_datam = np.matrix(_data)"
      ],
      "metadata": {
        "id": "mxppxOGpgbQf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_data.T.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "eHGu_axcgnf-",
        "outputId": "48d534d9-f3f0-48c4-d3d9-7231beacf7ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0           1           2           3           4           5   \\\n",
              "count  755.000000  755.000000  755.000000  755.000000  755.000000  755.000000   \n",
              "mean     0.000156    0.001655    0.002302    0.003973    0.005404    0.006715   \n",
              "std      0.011619    0.037021    0.073401    0.109735    0.145991    0.182294   \n",
              "min     -0.042102   -0.033115   -0.033386   -0.045707   -0.046940   -0.061555   \n",
              "25%     -0.006971   -0.003719   -0.005913   -0.006593   -0.005764   -0.006440   \n",
              "50%     -0.000168    0.000218   -0.000134    0.000491    0.000524    0.000025   \n",
              "75%      0.007290    0.004654    0.005255    0.006648    0.006462    0.006511   \n",
              "max      0.059061    1.000000    2.000000    3.000000    4.000000    5.000000   \n",
              "\n",
              "               6           7           8           9   ...          40  \\\n",
              "count  755.000000  755.000000  755.000000  755.000000  ...  755.000000   \n",
              "mean     0.008140    0.009503    0.010514    0.012255  ...    0.054295   \n",
              "std      0.218978    0.254849    0.291350    0.327692  ...    1.455853   \n",
              "min     -0.065764   -0.032658   -0.042606   -0.033406  ...   -0.082784   \n",
              "25%     -0.009267   -0.004088   -0.005906   -0.005975  ...   -0.009494   \n",
              "50%     -0.000493    0.000064   -0.000574    0.000281  ...    0.000815   \n",
              "75%      0.008803    0.004773    0.005157    0.006034  ...    0.012306   \n",
              "max      6.000000    7.000000    8.000000    9.000000  ...   40.000000   \n",
              "\n",
              "               41          42          43          44          45          46  \\\n",
              "count  755.000000  755.000000  755.000000  755.000000  755.000000  755.000000   \n",
              "mean     0.054405    0.055731    0.056169    0.058028    0.058148    0.060357   \n",
              "std      1.492212    1.528551    1.565071    1.601351    1.637953    1.674178   \n",
              "min     -0.056613   -0.024776   -0.094137   -0.044128   -0.228470   -0.058375   \n",
              "25%     -0.008544   -0.004325   -0.010665   -0.004565   -0.010652   -0.007956   \n",
              "50%     -0.000283    0.000480   -0.001489   -0.000403   -0.000872   -0.000194   \n",
              "75%      0.009035    0.004388    0.008589    0.004114    0.009286    0.006722   \n",
              "max     41.000000   42.000000   43.000000   44.000000   45.000000   46.000000   \n",
              "\n",
              "               47          48          49  \n",
              "count  755.000000  755.000000  755.000000  \n",
              "mean     0.063013    0.063727    0.064825  \n",
              "std      1.710509    1.746941    1.783311  \n",
              "min     -0.053760   -0.050026   -0.027561  \n",
              "25%     -0.005281   -0.007516   -0.004662  \n",
              "50%      0.000898   -0.000171   -0.000072  \n",
              "75%      0.006519    0.007489    0.004659  \n",
              "max     47.000000   48.000000   49.000000  \n",
              "\n",
              "[8 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd5a4e92-0d67-46ac-9945-64c4a4381909\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "      <td>755.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.001655</td>\n",
              "      <td>0.002302</td>\n",
              "      <td>0.003973</td>\n",
              "      <td>0.005404</td>\n",
              "      <td>0.006715</td>\n",
              "      <td>0.008140</td>\n",
              "      <td>0.009503</td>\n",
              "      <td>0.010514</td>\n",
              "      <td>0.012255</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054295</td>\n",
              "      <td>0.054405</td>\n",
              "      <td>0.055731</td>\n",
              "      <td>0.056169</td>\n",
              "      <td>0.058028</td>\n",
              "      <td>0.058148</td>\n",
              "      <td>0.060357</td>\n",
              "      <td>0.063013</td>\n",
              "      <td>0.063727</td>\n",
              "      <td>0.064825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.011619</td>\n",
              "      <td>0.037021</td>\n",
              "      <td>0.073401</td>\n",
              "      <td>0.109735</td>\n",
              "      <td>0.145991</td>\n",
              "      <td>0.182294</td>\n",
              "      <td>0.218978</td>\n",
              "      <td>0.254849</td>\n",
              "      <td>0.291350</td>\n",
              "      <td>0.327692</td>\n",
              "      <td>...</td>\n",
              "      <td>1.455853</td>\n",
              "      <td>1.492212</td>\n",
              "      <td>1.528551</td>\n",
              "      <td>1.565071</td>\n",
              "      <td>1.601351</td>\n",
              "      <td>1.637953</td>\n",
              "      <td>1.674178</td>\n",
              "      <td>1.710509</td>\n",
              "      <td>1.746941</td>\n",
              "      <td>1.783311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.042102</td>\n",
              "      <td>-0.033115</td>\n",
              "      <td>-0.033386</td>\n",
              "      <td>-0.045707</td>\n",
              "      <td>-0.046940</td>\n",
              "      <td>-0.061555</td>\n",
              "      <td>-0.065764</td>\n",
              "      <td>-0.032658</td>\n",
              "      <td>-0.042606</td>\n",
              "      <td>-0.033406</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.082784</td>\n",
              "      <td>-0.056613</td>\n",
              "      <td>-0.024776</td>\n",
              "      <td>-0.094137</td>\n",
              "      <td>-0.044128</td>\n",
              "      <td>-0.228470</td>\n",
              "      <td>-0.058375</td>\n",
              "      <td>-0.053760</td>\n",
              "      <td>-0.050026</td>\n",
              "      <td>-0.027561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.006971</td>\n",
              "      <td>-0.003719</td>\n",
              "      <td>-0.005913</td>\n",
              "      <td>-0.006593</td>\n",
              "      <td>-0.005764</td>\n",
              "      <td>-0.006440</td>\n",
              "      <td>-0.009267</td>\n",
              "      <td>-0.004088</td>\n",
              "      <td>-0.005906</td>\n",
              "      <td>-0.005975</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009494</td>\n",
              "      <td>-0.008544</td>\n",
              "      <td>-0.004325</td>\n",
              "      <td>-0.010665</td>\n",
              "      <td>-0.004565</td>\n",
              "      <td>-0.010652</td>\n",
              "      <td>-0.007956</td>\n",
              "      <td>-0.005281</td>\n",
              "      <td>-0.007516</td>\n",
              "      <td>-0.004662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.000168</td>\n",
              "      <td>0.000218</td>\n",
              "      <td>-0.000134</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>-0.000574</td>\n",
              "      <td>0.000281</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>-0.000283</td>\n",
              "      <td>0.000480</td>\n",
              "      <td>-0.001489</td>\n",
              "      <td>-0.000403</td>\n",
              "      <td>-0.000872</td>\n",
              "      <td>-0.000194</td>\n",
              "      <td>0.000898</td>\n",
              "      <td>-0.000171</td>\n",
              "      <td>-0.000072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.007290</td>\n",
              "      <td>0.004654</td>\n",
              "      <td>0.005255</td>\n",
              "      <td>0.006648</td>\n",
              "      <td>0.006462</td>\n",
              "      <td>0.006511</td>\n",
              "      <td>0.008803</td>\n",
              "      <td>0.004773</td>\n",
              "      <td>0.005157</td>\n",
              "      <td>0.006034</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012306</td>\n",
              "      <td>0.009035</td>\n",
              "      <td>0.004388</td>\n",
              "      <td>0.008589</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.009286</td>\n",
              "      <td>0.006722</td>\n",
              "      <td>0.006519</td>\n",
              "      <td>0.007489</td>\n",
              "      <td>0.004659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.059061</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>49.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd5a4e92-0d67-46ac-9945-64c4a4381909')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd5a4e92-0d67-46ac-9945-64c4a4381909 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd5a4e92-0d67-46ac-9945-64c4a4381909');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_datam.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilzdqh1k9S8Y",
        "outputId": "d8711acc-033a-4615-ba47-7ee88abe408d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 755)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handler Class and Utils Function"
      ],
      "metadata": {
        "id": "pyalGnf8i6pG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EP1EtTdKic6L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def gram_schmidt_algorithm(A):\n",
        "    \"\"\"\n",
        "    O(d^2k)\n",
        "    \"\"\"\n",
        "    for i in range(A.shape[0]):\n",
        "        q = A[i, :]\n",
        "        for j in range(i):\n",
        "            q = q - np.dot(A[j,:], A[i,:]) * A[j,:]\n",
        "        q = q / np.sqrt(np.dot(q, q))\n",
        "        A[i,:] = q\n",
        "    return A\n",
        "\n",
        "def cayley_transformation(A):\n",
        "    \"\"\"\n",
        "    A is (d,k) matrix\n",
        "    T = \n",
        "    O()\n",
        "    \"\"\"\n",
        "    I = np.eye(A.shape[0])\n",
        "    Q = np.matmul(np.linalg.inv(I+A),(I-A))\n",
        "    return Q\n",
        "\n",
        "def random_matrix(shape, limits_gap=200, center=0.5):\n",
        "    rmat = np.random.random(shape)\n",
        "    while np.linalg.matrix_rank(rmat) < min(shape[0],shape[1]):\n",
        "        rmat = np.random.random(shape)\n",
        "    return limits_gap*(rmat-center)\n",
        "\n",
        "class Data_Handler:\n",
        "    def __init__(self, n, k, d, T, S, R):\n",
        "        \"\"\"\n",
        "        R is a n x (T + S) numpy array\n",
        "        d is an integer that represents the number of time lags\n",
        "        d <= k\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.k = k\n",
        "        self.d = d\n",
        "        self.T = T\n",
        "        self.S = S\n",
        "        self.R = R\n",
        "        assert(d<=k)\n",
        "        assert(R.shape[0]==n)\n",
        "        assert(R.shape[1]==(T+S))\n",
        "        self._compute_optimizers()\n",
        "        pass\n",
        "\n",
        "    def get_string(self):\n",
        "        return f\"{self.n}-{self.k}-{self.d}-{self.T}-{self.S}\"\n",
        "\n",
        "    def _compute_optimizers(self):\n",
        "        self.sum_RtdTRtd_dT_altD = np.zeros((self.d, self.d))  # d x d\n",
        "        self.sum_RtdTRt_dT_altN = np.zeros((self.d, 1))  # d x 1\n",
        "        self.list_RtdTRtd = []\n",
        "        self.list_RtdTRt = []\n",
        "        self.list_norm_Rt = []\n",
        "        for t in range(self.d):\n",
        "            r_t = self.R[:, t].reshape(self.n, 1)  # n x 1\n",
        "            self.list_RtdTRtd += [None]\n",
        "            self.list_RtdTRt += [None]\n",
        "            self.list_norm_Rt += [np.linalg.norm(r_t, 2)]\n",
        "        for t in range(self.d, self.T+self.S):\n",
        "            r_t = self.R[:, t].reshape(self.n, 1)  # n x 1\n",
        "            r_td = self.R[:, t-self.d:t]  # n x d\n",
        "            self.list_RtdTRtd += [np.matmul(r_td.T, r_td)]\n",
        "            self.list_RtdTRt += [np.matmul(r_td.T, r_t)]\n",
        "            self.list_norm_Rt += [np.linalg.norm(r_t, 2)]\n",
        "        for t in range(self.d, self.T):\n",
        "            self.sum_RtdTRtd_dT_altD += self.list_RtdTRtd[t]\n",
        "            self.sum_RtdTRt_dT_altN += self.list_RtdTRt[t]\n",
        "\n",
        "    def compute_reward(self, beta, A):\n",
        "        Abeta = np.matmul(A, beta)  # d x 1\n",
        "        reward_sum = 0\n",
        "        for t in range(self.T, self.T + self.S):\n",
        "            reward_sum += np.matmul(self.list_RtdTRt[t].T, Abeta) / (self.list_norm_Rt[t] * np.sqrt(np.matmul(Abeta.T, np.matmul(self.list_RtdTRtd[t], Abeta))))\n",
        "        reward = reward_sum / self.S\n",
        "        return reward\n",
        "\n",
        "    def compute_loss(self, beta, A):\n",
        "        Abeta = np.matmul(A, beta)  # d x 1\n",
        "        loss_sum = 0\n",
        "        for t in range(self.d, self.T):\n",
        "            loss_sum += self.list_norm_Rt[t]\n",
        "            loss_sum += -2*np.matmul(self.list_RtdTRt[t].T, Abeta)\n",
        "            loss_sum += np.matmul(Abeta.T, np.matmul(self.list_RtdTRtd[t], Abeta))\n",
        "        loss = loss_sum / (2*(self.T - self.d + 1))\n",
        "        return loss\n",
        "\n",
        "    def compute_loss_gradient_beta(self, beta, A):\n",
        "        beta_grad = np.matmul(A.T, np.matmul(self.sum_RtdTRtd_dT_altD, np.matmul(A, beta))) - np.matmul(A.T, self.sum_RtdTRt_dT_altN)\n",
        "        beta_grad = beta_grad / (self.T - self.d + 1)\n",
        "        return beta_grad\n",
        "\n",
        "    def compute_loss_gradient_A(self, beta, A):\n",
        "        A_grad = np.matmul(self.sum_RtdTRtd_dT_altD, np.matmul(A, beta)) - self.sum_RtdTRt_dT_altN\n",
        "        A_grad = np.matmul(A_grad, beta.T)\n",
        "        A_grad = A_grad / (self.T - self.d + 1)\n",
        "        return A_grad\n",
        "\n",
        "    def compute_loss_gradient_beta_A(self, beta, A):\n",
        "        temp = np.matmul(self.sum_RtdTRtd_dT_altD, np.matmul(A, beta))\n",
        "        beta_grad = np.matmul(A.T, temp) - np.matmul(A.T, self.sum_RtdTRt_dT_altN)\n",
        "        beta_grad = beta_grad / (self.T - self.d + 1)\n",
        "        A_grad = temp - self.sum_RtdTRt_dT_altN\n",
        "        A_grad = np.matmul(A_grad, beta.T)\n",
        "        A_grad = A_grad / (self.T - self.d + 1)\n",
        "        return beta_grad, A_grad\n",
        "\n",
        "    def compute_reward_gradient_beta(self, beta, A):\n",
        "        T1 = np.zeros((self.d,1))\n",
        "        T2 = np.zeros((self.d,self.d))\n",
        "        Abeta = np.matmul(A, beta)  # d x 1\n",
        "        for t in range(self.T, self.T + self.S):\n",
        "            Ftbeta_norm = float(np.sqrt(np.matmul(Abeta.T,np.matmul(self.list_RtdTRtd[t],Abeta))))\n",
        "            RtFtbeta_scalar = float(np.matmul(self.list_RtdTRt[t].T, Abeta))\n",
        "            T1 += self.list_RtdTRt[t]/(Ftbeta_norm * self.list_norm_Rt[t])\n",
        "            T2 += (RtFtbeta_scalar/(self.list_norm_Rt[t]*Ftbeta_norm**3)  * self.list_RtdTRtd[t])\n",
        "        grad_beta = np.matmul(A.T, T1) - np.matmul(A.T, np.matmul(T2,Abeta))\n",
        "        grad_beta =  grad_beta / self.S\n",
        "        return grad_beta\n",
        "\n",
        "    def compute_reward_gradient_A(self, beta, A):\n",
        "        T1 = np.zeros((self.d,1))\n",
        "        T2 = np.zeros((self.d,self.d))\n",
        "        Abeta = np.matmul(A, beta)  # d x 1\n",
        "        for t in range(self.T, self.T + self.S):\n",
        "            Ftbeta_norm = float(np.sqrt(np.matmul(Abeta.T,np.matmul(self.list_RtdTRtd[t],Abeta))))\n",
        "            RtFtbeta_scalar = float(np.matmul(self.list_RtdTRt[t].T, Abeta))\n",
        "            T1 += self.list_RtdTRt[t]/(Ftbeta_norm * self.list_norm_Rt[t])\n",
        "            T2 += (RtFtbeta_scalar/(self.list_norm_Rt[t]*Ftbeta_norm**3)  * self.list_RtdTRtd[t])\n",
        "        grad_A = np.matmul(T1, beta.T) - np.matmul(np.matmul(T2, Abeta), beta.T)\n",
        "        grad_A =  grad_A / self.S\n",
        "        return grad_A\n",
        "    \n",
        "    def compute_reward_gradient_beta_A(self, beta, A):\n",
        "        T1 = np.zeros((self.d,1))\n",
        "        T2 = np.zeros((self.d,self.d))\n",
        "        Abeta = np.matmul(A, beta)  # d x 1\n",
        "        for t in range(self.T, self.T + self.S):\n",
        "            Ftbeta_norm = float(np.sqrt(np.matmul(Abeta.T,np.matmul(self.list_RtdTRtd[t],Abeta))))\n",
        "            RtFtbeta_scalar = float(np.matmul(self.list_RtdTRt[t].T, Abeta))\n",
        "            T1 += self.list_RtdTRt[t]/(Ftbeta_norm * self.list_norm_Rt[t])\n",
        "            T2 += (RtFtbeta_scalar/(self.list_norm_Rt[t]*Ftbeta_norm**3)  * self.list_RtdTRtd[t])\n",
        "        grad_beta = np.matmul(A.T, T1) - np.matmul(A.T, np.matmul(T2,Abeta))\n",
        "        grad_beta =  grad_beta / self.S\n",
        "        grad_A = np.matmul(T1, beta.T) - np.matmul(np.matmul(T2, Abeta), beta.T)\n",
        "        grad_A =  grad_A / self.S\n",
        "        return grad_beta, grad_A\n",
        "    \n",
        "    def compute_orthogonal_condition_normF(self, A):\n",
        "        return np.sum((np.matmul(A, A.T) - np.eye(A.shape[0]))**2)\n",
        "\n",
        "    def compute_orthogonal_condition_normF_gradient_A(self, A):\n",
        "        return -4.0*np.matmul(np.eye(A.shape[0]) - np.matmul(A, A.T), A)\n",
        "\n",
        "    def linear_l2_regression(self, A):\n",
        "        \"\"\"\n",
        "        O(d^2k+k^3) = O(k^3)\n",
        "        \"\"\"\n",
        "        beta = np.matmul(np.matmul(A.T,self.sum_RtdTRtd_dT_altD),A)\n",
        "        beta = np.linalg.inv(beta)\n",
        "        beta = np.matmul(beta, np.matmul(A.T,self.sum_RtdTRt_dT_altN))\n",
        "        return beta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logger "
      ],
      "metadata": {
        "id": "EaglZjMCm5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gif"
      ],
      "metadata": {
        "id": "vlkftZgHYVXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import gif\n",
        "\n",
        "class Logger:\n",
        "    def __init__(self, log_name: str, data_handler:Data_Handler):\n",
        "        self.log_name = log_name\n",
        "        self.list_R = []\n",
        "        self.list_L = []\n",
        "        self.list_O = []\n",
        "        self.EA_RLO_logs = dict()\n",
        "        self.EA_archive_RLO = dict()\n",
        "        self.data_handler = data_handler\n",
        "        pass\n",
        "\n",
        "    def clear(self):\n",
        "        self.list_R = []\n",
        "        self.list_L = []\n",
        "        self.list_O = []\n",
        "        self.EA_RLO_logs = dict()\n",
        "        self.EA_archive_RLO = dict()\n",
        "        pass\n",
        "\n",
        "    def log_RLO(self, R, L, O):\n",
        "        self.list_L += [float(L)]\n",
        "        self.list_R += [float(R)]\n",
        "        self.list_O += [float(O)]\n",
        "        pass\n",
        "    \n",
        "    def log_EA_RLO(self,gen,R,L,O):\n",
        "        R = float(R)\n",
        "        L = float(L)\n",
        "        O = float(O)\n",
        "        if gen in self.EA_RLO_logs.keys():\n",
        "            self.EA_RLO_logs[gen][0].append(R)\n",
        "            self.EA_RLO_logs[gen][1].append(L)\n",
        "            self.EA_RLO_logs[gen][2].append(O)\n",
        "        else:\n",
        "            self.EA_RLO_logs[gen] =  [[R],[L],[O]]\n",
        "        pass  \n",
        "        \n",
        "    def log_EA_Population(self, gen, P): \n",
        "        R = [float(P[i].R) for i in range(len(P))]\n",
        "        L = [float(P[i].L) for i in range(len(P))]\n",
        "        O = [float(self.data_handler.compute_orthogonal_condition_normF(P[i].A)) for i in range(len(P))]\n",
        "        self.EA_RLO_logs[gen] = [R,L,O]\n",
        "\n",
        "    def log_archive(self,gen,Arch):\n",
        "        R = [float(Arch[i].R) for i in range(len(Arch))]\n",
        "        L = [float(Arch[i].L) for i in range(len(Arch))]\n",
        "        O = [float(self.data_handler.compute_orthogonal_condition_normF(Arch[i].A)) for i in range(len(Arch))]\n",
        "        self.EA_archive_RLO[gen] = [R,L,O]\n",
        "        pass\n",
        "    \n",
        "    def dump(self,folder):\n",
        "        if len(self.list_L) > 0:\n",
        "            df = pd.DataFrame()\n",
        "            df['R'] = self.list_R\n",
        "            df['L'] = self.list_L\n",
        "            df['O'] = self.list_O\n",
        "            fname = \"RLO_\"+self.log_name+\".csv\"\n",
        "            fpath = os.path.join(folder,fname)\n",
        "            df.to_csv(fpath, index = False)\n",
        "            print(f\" {self.log_name} : dumped ROL\")\n",
        "        \n",
        "        if len(self.EA_RLO_logs) > 0:\n",
        "            df = pd.DataFrame()\n",
        "            for k,v in self.EA_RLO_logs.items():\n",
        "                df[f\"{k}_R\"] = v[0]\n",
        "                df[f\"{k}_L\"] = v[1]\n",
        "                df[f\"{k}_O\"] = v[2]\n",
        "            fname = \"EARLO_\"+self.log_name+\".csv\"\n",
        "            fpath = os.path.join(folder,fname)\n",
        "            df.to_csv(fpath, index = False)\n",
        "            print(f\" {self.log_name} : dumped EARLO\")\n",
        "\n",
        "        if len(self.EA_archive_RLO) > 0:\n",
        "            l = []\n",
        "            for k,v in self.EA_archive_RLO.items():\n",
        "                l.append((f\"{k}_R\", pd.Series(v[0])))\n",
        "                l.append((f\"{k}_L\", pd.Series(v[1])))\n",
        "                l.append((f\"{k}_O\", pd.Series(v[2])))\n",
        "            df = pd.DataFrame(dict(l))\n",
        "            fname = \"EAarchiveRLO_\"+self.log_name+\".csv\"\n",
        "            fpath = os.path.join(folder,fname)\n",
        "            df.to_csv(fpath, index = False)\n",
        "            print(f\" {self.log_name} : dumped EAarchiveROL\")\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def load(self,rlo_file=None, earlo_file=None, eaarchiverl_file=None):\n",
        "        if rlo_file is not None:\n",
        "            df = pd.read_csv(rlo_file)\n",
        "            self.list_R = list(df['R'])\n",
        "            self.list_L = list(df['L'])\n",
        "            self.list_O = list(df['O'])\n",
        "        else:\n",
        "            self.list_R = []\n",
        "            self.list_L = []\n",
        "            self.list_O = []\n",
        "        \n",
        "        self.EA_RLO_logs = dict()\n",
        "        if earlo_file is not None:\n",
        "            df = pd.read_csv(earlo_file)\n",
        "            for k in df.columns:\n",
        "                g = int(k.split('_')[0])\n",
        "                if g in self.EA_RLO_logs.keys():\n",
        "                    continue\n",
        "                self.EA_RLO_logs[g] = [list(df[g+\"_R\"]),list(df[g+\"_L\"]),list(df[g+\"_O\"])]\n",
        "        \n",
        "        self.EA_archive_RLO = dict()\n",
        "        if eaarchiverl_file is not None:\n",
        "            df = pd.read_csv(eaarchiverl_file)\n",
        "            for k in df.columns:\n",
        "                g = int(k.split('_')[0])\n",
        "                if g in self.EA_archive_RLO.keys():\n",
        "                    continue\n",
        "                self.EA_archive_RLO[g] = [list(df[g+\"_R\"]),list(df[g+\"_L\"]),list(df[g+\"_O\"])]\n",
        "        pass\n",
        "\n",
        "\n",
        "    def plot_scatter_LR(self, x_scale=\"linear\", y_scale=\"linear\", save=False, file_name=\"fig.png\"):\n",
        "        sns.set_style(\"darkgrid\")\n",
        "        sns.set_palette(\"bright\")\n",
        "        x_label = \"Reward\"\n",
        "        y_label = \"Loss\"\n",
        "        ax = sns.scatterplot(x=self.list_R, y=self.list_L)\n",
        "        ax.set(xscale=x_scale, yscale=y_scale, xlabel=x_label, ylabel=y_label)\n",
        "        if save:\n",
        "            plt.savefig(file_name)\n",
        "        plt.show()\n",
        "\n",
        "    def dist_plot(self, save=False, filename='distplot.png'):\n",
        "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 4))\n",
        "        sns.set_style('whitegrid')\n",
        "        sns.distplot(self.list_R, label='Reward', ax=ax1)\n",
        "        ax1.set(title='Distribution of Rewards')\n",
        "        sns.distplot(self.list_L, label='Loss', ax=ax2)\n",
        "        ax2.set(title='Distribution of Loss')\n",
        "        ax1.legend()\n",
        "        ax2.legend()\n",
        "        if save:\n",
        "            plt.savefig(filename)\n",
        "        plt.show()\n",
        "    \n",
        "    def get_gif_from_RL_log_dict(self, duration=200,style='seaborn',xscale='log',yscale='log',dpi=300,lam_margins=1.2, set_boundaries = False):\n",
        "        plt.style.use(style)\n",
        "        gif.options.matplotlib[\"dpi\"] = dpi\n",
        "\n",
        "        def get_min_max_limits(lam):\n",
        "            R_max = -float('inf')\n",
        "            R_min = float('inf')\n",
        "            L_max = -float('inf')\n",
        "            L_min = float('inf')\n",
        "            for k,v in self.EA_RLO_logs.items():\n",
        "                R_max = max(np.max(v[0]),R_max)\n",
        "                R_min = min(np.min(v[0]),R_min)\n",
        "                L_max = max(np.max(v[1]),L_max)\n",
        "                L_min = min(np.min(v[1]),L_min)\n",
        "            return 0.5*np.asarray([  (1+lam)*R_min+(1-lam)*R_max, (1-lam)*R_min+(1+lam)*R_max, (1+lam)*L_min+(1-lam)*L_max, (1-lam)*L_min+(1+lam)*L_max])\n",
        "            \n",
        "        limits = get_min_max_limits(lam_margins)\n",
        "        @gif.frame\n",
        "        def plot(key,value):\n",
        "            sns.set(style=\"whitegrid\")\n",
        "            ax = sns.scatterplot(x=value[0], y=value[1], color='red',)\n",
        "            ax.set_title(f\"{self.log_name} Generation : {key}\")\n",
        "            if set_boundaries:\n",
        "                ax.set_xlim([limits[0], limits[1]])\n",
        "                ax.set_ylim([limits[2], limits[3]])\n",
        "\n",
        "        frames = [ plot(k,v) for k,v in self.EA_RLO_logs.items()]\n",
        "        filename = f\"{self.log_name}\" + \".gif\"\n",
        "        gif.save(frames, filename, duration=duration)\n",
        "        pass\n",
        "\n",
        "    def get_grid_plot_from_RL_log_dict(self,period,plot_grid_shape):\n",
        "        pass\n",
        "\n",
        "    def get_tragectory_gif(self,duration=200,style='seaborn',xscale='log',yscale='log',dpi=300,lam_margins=1.2,set_boundaries = False):\n",
        "        plt.style.use(style)\n",
        "        gif.options.matplotlib[\"dpi\"] = dpi\n",
        "\n",
        "        def get_min_max_limits(lam):\n",
        "            R_max = -float('inf')\n",
        "            R_min = float('inf')\n",
        "            L_max = -float('inf')\n",
        "            L_min = float('inf')\n",
        "            for k,v in self.EA_RLO_logs.items():\n",
        "                R_max = max(np.max(v[0]),R_max)\n",
        "                R_min = min(np.min(v[0]),R_min)\n",
        "                L_max = max(np.max(v[1]),L_max)\n",
        "                L_min = min(np.min(v[1]),L_min)\n",
        "            return 0.5*np.asarray([  (1+lam)*R_min+(1-lam)*R_max, (1-lam)*R_min+(1+lam)*R_max, (1+lam)*L_min+(1-lam)*L_max, (1-lam)*L_min+(1+lam)*L_max])\n",
        "        \n",
        "        limits = get_min_max_limits(lam_margins)\n",
        "        @gif.frame\n",
        "        def plot(gen_i):\n",
        "            fig, ax = plt.subplots()\n",
        "            for point in range(len(self.EA_RLO_logs[gen_i][0])):\n",
        "                point_Rs = [self.EA_RLO_logs[gg][0][point] for gg in range(gen_i+1)]\n",
        "                points_Ls = [self.EA_RLO_logs[gg][1][point] for gg in range(gen_i+1)]\n",
        "                # ax.plot(point_Rs, points_Ls, label=f'Point {point+1}')\n",
        "                ax.plot(point_Rs, points_Ls)\n",
        "                if set_boundaries:\n",
        "                    ax.set_xlim([limits[0], limits[1]])\n",
        "                    ax.set_ylim([limits[2], limits[3]])\n",
        "\n",
        "            # Set plot properties\n",
        "            ax.set_xlabel('Reward')\n",
        "            ax.set_ylabel('Loss')\n",
        "            ax.set_title(f\"Trajectories of Points: {gen_i}\")\n",
        "            ax.set_yscale(yscale)\n",
        "            ax.set_xscale(xscale)\n",
        "\n",
        "        gen_max = len(self.EA_RLO_logs)\n",
        "        frames = [ plot(i) for i in range(gen_max)]\n",
        "        filename = f\"{self.log_name}-tragectory\" + \".gif\"\n",
        "        gif.save(frames, filename, duration=duration)\n",
        "        pass\n",
        "\n",
        "    def show_tragetctory_plot(self,style='seaborn',xscale='log',yscale='log'):\n",
        "        plt.style.use(style)\n",
        "        fig, ax = plt.subplots()\n",
        "        gen_max = len(self.EA_RLO_logs)\n",
        "        # Plot each point's trajectory as a line\n",
        "        for point in range(len(self.EA_RLO_logs[0][0])):\n",
        "            point_Rs = [self.EA_RLO_logs[gg][0][point] for gg in range(gen_max)]\n",
        "            points_Ls = [self.EA_RLO_logs[gg][1][point] for gg in range(gen_max)]\n",
        "            ax.plot(point_Rs, points_Ls, label=f'Point {point+1}')\n",
        "\n",
        "        # Set plot properties\n",
        "        ax.set_xlabel('Reward')\n",
        "        ax.set_ylabel('Loss')\n",
        "        ax.set_title('Trajectories of Points')\n",
        "        ax.set_yscale(yscale)\n",
        "        ax.set_xscale(xscale)\n",
        "        # ax.legend()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "ayNzrUuAm7Qu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Method"
      ],
      "metadata": {
        "id": "5MoPHB8Yjgvc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "XVi3VnWL_l58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Baseline_Method:\n",
        "    def __init__(self, data_handler: Data_Handler):\n",
        "        self.n = data_handler.n\n",
        "        self.k = data_handler.k\n",
        "        self.d = data_handler.d\n",
        "        self.T = data_handler.T\n",
        "        self.S = data_handler.S\n",
        "        self.data_handler = data_handler\n",
        "        pass\n",
        "\n",
        "    def get_string(self):\n",
        "        return \"baseline\"\n",
        "        \n",
        "    def run(self, iter_max=100, logger:Logger=None):\n",
        "        beta_opt = None\n",
        "        A_opt = None\n",
        "        R_opt = -float('inf')\n",
        "        L_opt = float('inf')\n",
        "        for iter in tqdm(range(iter_max), desc='Baseline Method'):\n",
        "            M = random_matrix((self.d, self.k))\n",
        "            A = gram_schmidt_algorithm(M)\n",
        "            beta = self.data_handler.linear_l2_regression(A)\n",
        "            R = self.data_handler.compute_reward(beta, A)\n",
        "            L = self.data_handler.compute_loss(beta, A)\n",
        "            if logger is not None:\n",
        "                logger.log_RLO(R,L,self.data_handler.compute_orthogonal_condition_normF(A))\n",
        "            if R > R_opt:\n",
        "                beta_opt = beta\n",
        "                A_opt = A\n",
        "                R_opt = R\n",
        "                L_opt = L\n",
        "        return beta_opt, A_opt"
      ],
      "metadata": {
        "id": "PTld5WMnji0u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ],
      "metadata": {
        "id": "D4Yr5ZVno39p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50\n",
        "k = 21\n",
        "d = 20\n",
        "T = 600\n",
        "assert(T<_datam.shape[1])\n",
        "S = _datam.shape[1]-T\n",
        "\n",
        "dh = Data_Handler(n,k,d,T,S,_datam)"
      ],
      "metadata": {
        "id": "ihjm0bXijoMp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blm = Baseline_Method(dh)\n",
        "logger_name = blm.get_string()+'-'+dh.get_string()\n",
        "logger_bml = Logger(logger_name, dh)"
      ],
      "metadata": {
        "id": "VBOiaVrpkonF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, A = blm.run(10000,logger_bml)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_1M1KcykwYA",
        "outputId": "32e5f0cd-9abd-428e-f7dc-0534d67a072a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Baseline Method: 100%|██████████| 10000/10000 [09:55<00:00, 16.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVlWbSwjbu3y",
        "outputId": "e78ce6c0-815c-4753-da7e-487144c00e77"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.216484604989007e-28"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger_bml.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "Y2-rILUk1mqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee520c5c-7297-4f4c-bbcd-1e9a19e3e14d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " baseline-50-21-20-600-155 : dumped ROL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger_bml.plot_scatter_LR('linear','log')"
      ],
      "metadata": {
        "id": "oRuTOZgxtfa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_bml.dist_plot()"
      ],
      "metadata": {
        "id": "KpnumEQb5dKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dtTui8Ry6o7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Based Methods"
      ],
      "metadata": {
        "id": "IeMBJGJK-HuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Internal Methods"
      ],
      "metadata": {
        "id": "TLEoGYVn-Pen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class U_A_Method:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "class U_A_Method_1(U_A_Method):\n",
        "    def __init__(self, alpha, data_handler:Data_Handler):\n",
        "        super().__init__()\n",
        "        self.data_handler = data_handler\n",
        "        self.itter = alpha[0]\n",
        "        self.learning_rate = alpha[1]\n",
        "        self.weight_R = alpha[2]\n",
        "        self.weight_L = alpha[3]\n",
        "        self.weight_O = alpha[4]\n",
        "        pass\n",
        "    def get_delta_A(self, beta, A):\n",
        "        R_grad_A = self.data_handler.compute_reward_gradient_A(beta, A)\n",
        "        L_grad_A = self.data_handler.compute_loss_gradient_A(beta, A)\n",
        "        O_grad_A = self.data_handler.compute_orthogonal_condition_normF_gradient_A(A)\n",
        "        delta = self.weight_R*R_grad_A-self.weight_L*L_grad_A-self.weight_O*O_grad_A\n",
        "        return self.learning_rate*delta\n",
        "    def get_string(self):\n",
        "        return f\"U_A[{self.itter},{int(10000*self.learning_rate)},{int(10000*self.weight_R)},{int(10000*self.weight_L)},{int(10000*self.weight_O)}]\"\n",
        "\n",
        "\n",
        "class U_beta_Method:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "class U_beta_Method_1(U_beta_Method):\n",
        "    def __init__(self, phi, data_handler:Data_Handler):\n",
        "        super().__init__()\n",
        "        self.data_handler = data_handler\n",
        "        self.itter = phi[0]\n",
        "        self.learning_rate = phi[1]\n",
        "        self.weight_R = phi[2]\n",
        "        self.weight_L = phi[3]\n",
        "        pass\n",
        "    def get_delta_beta(self, beta, A, A_new):\n",
        "        R_grad_beta = self.data_handler.compute_reward_gradient_beta(beta, A)\n",
        "        L_grad_beta = self.data_handler.compute_loss_gradient_beta(beta, A)\n",
        "        delta = self.weight_R*R_grad_beta-self.weight_L*L_grad_beta\n",
        "        return self.learning_rate*delta\n",
        "    def get_string(self):\n",
        "        return f\"U_beta[{self.itter},{int(10000*self.learning_rate)},{int(10000*self.weight_R)},{int(10000*self.weight_L)}]\"\n",
        "class U_beta_Method_2(U_beta_Method):\n",
        "    def __init__(self, phi, data_handler:Data_Handler):\n",
        "        super().__init__()\n",
        "        self.data_handler = data_handler\n",
        "        self.itter = phi[0]\n",
        "        self.learning_rate = phi[1]\n",
        "        self.weight_R = phi[2]\n",
        "        self.weight_L = phi[3]\n",
        "        self.weight_reg = phi[4]\n",
        "        pass\n",
        "    def get_delta_beta(self, beta, A, A_new):\n",
        "        R_grad_beta = self.data_handler.compute_reward_gradient_beta(beta, A)\n",
        "        L_grad_beta = self.data_handler.compute_loss_gradient_beta(beta, A)\n",
        "        beta_reg = self.data_handler.linear_l2_regression(A_new)\n",
        "\n",
        "        delta = self.weight_R*R_grad_beta-self.weight_L*L_grad_beta\n",
        "        delta = (1-self.weight_reg)*self.learning_rate*delta\n",
        "        delta += self.weight_reg*(beta_reg-2*beta) \n",
        "        return delta\n",
        "    def get_string(self):\n",
        "        return f\"U_beta[{self.itter},{int(10000*self.learning_rate)},{int(10000*self.weight_R)},{int(10000*self.weight_L)},{int(10000*self.weight_reg)}]\"\n",
        "\n",
        "class U_O_Method:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "class U_O_Method_1(U_O_Method):\n",
        "    def __init__(self, lamb, data_handler:Data_Handler):\n",
        "        super().__init__()\n",
        "        self.data_handler = data_handler\n",
        "        self.iter_max = lamb[0]\n",
        "        self.learning_rate_A = lamb[1]\n",
        "        self.learning_rate_beta = lamb[2]\n",
        "        self.weight_reg = lamb[3]\n",
        "        pass\n",
        "    def get_new_beta_A(self, beta, A):\n",
        "        A_i = random_matrix(A.shape)\n",
        "        A_i = gram_schmidt_algorithm(A_i)\n",
        "        beta_i = self.data_handler.linear_l2_regression(A_i)\n",
        "        A_opt = A_i\n",
        "        beta_opt = beta_i\n",
        "        R_opt = self.data_handler.compute_reward(beta_opt,A_opt)\n",
        "        L_opt = self.data_handler.compute_loss(beta_opt,A_opt)\n",
        "        for iter in tqdm(range(self.iter_max),desc=\"U_O_Method_1:get_new_beta_A\"):\n",
        "            deltaA = self.learning_rate_A *(A - A_i)\n",
        "            T_i =  0.5*(np.matmul(deltaA.T,A_i) - np.matmul(A_i.T,deltaA))\n",
        "            Q = cayley_transformation(T_i)\n",
        "            A_i = np.matmul(A_i, Q)\n",
        "            beta_reg = self.data_handler.linear_l2_regression(A_i)\n",
        "            beta_grad = self.data_handler.compute_reward_gradient_beta(beta_i, A_i)\n",
        "            beta_i = beta_i + self.learning_rate_beta*((1-self.weight_reg)*beta_grad+self.weight_reg*(beta_reg-beta_i))\n",
        "            R_i = self.data_handler.compute_reward(beta_i,A_i)\n",
        "            L_i = self.data_handler.compute_loss(beta_i,A_i)\n",
        "            if R_i > R_opt:\n",
        "                A_opt = A_i\n",
        "                beta_opt = beta_i\n",
        "                R_opt = R_i\n",
        "        return beta_opt, A_opt\n",
        "    def get_string(self):\n",
        "        return f\"U_O[{self.iter_max},{int(10000*self.learning_rate_A)},{int(10000*self.learning_rate_beta)},{int(10000*self.weight_reg)}]\""
      ],
      "metadata": {
        "id": "b2SlMWQY-ORH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPI Method"
      ],
      "metadata": {
        "id": "BmQh1gysBJZi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "h9tcOiQkBjA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class OPI:\n",
        "    def __init__(self,data_handler:Data_Handler, U_beta:U_beta_Method, U_A:U_A_Method):\n",
        "        self.n = data_handler.n\n",
        "        self.k = data_handler.k\n",
        "        self.d = data_handler.d\n",
        "        self.T = data_handler.T\n",
        "        self.S = data_handler.S\n",
        "        self.data_handler = data_handler\n",
        "        self.U_beta = U_beta\n",
        "        self.U_A = U_A\n",
        "        pass\n",
        "\n",
        "    def run(self, iter_max=100, logger:Logger=None):\n",
        "        A = random_matrix((self.d, self.k))\n",
        "        A = gram_schmidt_algorithm(A)\n",
        "        beta = self.data_handler.linear_l2_regression(A)\n",
        "        beta_opt = beta\n",
        "        A_opt = A\n",
        "        R_opt = self.data_handler.compute_reward(beta,A)\n",
        "        L_opt = self.data_handler.compute_loss(beta,A)\n",
        "        if logger is not None:\n",
        "            logger.log_RLO(R_opt,L_opt,self.data_handler.compute_orthogonal_condition_normF(A_opt))\n",
        "        for iter in tqdm(range(iter_max), desc='OPI Scheme'):\n",
        "            deltaA = self.U_A.get_delta_A(beta,A)\n",
        "            T_i =  0.5*(np.matmul(deltaA.T,A) - np.matmul(A.T,deltaA))\n",
        "            Q = cayley_transformation(T_i)\n",
        "            AQ = np.matmul(A,Q)\n",
        "            beta = beta + self.U_beta.get_delta_beta(beta,A,AQ)\n",
        "            A = AQ\n",
        "            R = self.data_handler.compute_reward(beta,A)\n",
        "            L = self.data_handler.compute_loss(beta,A)\n",
        "            if R > R_opt:\n",
        "                A_opt = A\n",
        "                beta_opt = beta\n",
        "                R_opt = R\n",
        "                L_opt = L\n",
        "            if logger is not None:\n",
        "                logger.log_RLO(R,L,self.data_handler.compute_orthogonal_condition_normF(A))\n",
        "        return beta_opt, A_opt\n",
        "\n",
        "    def get_string(self):\n",
        "        return f\"opi-{self.U_beta.get_string()}-{self.U_A.get_string()}\"\n",
        "        \n"
      ],
      "metadata": {
        "id": "ZoYZgYiGBKwl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments"
      ],
      "metadata": {
        "id": "SwtaKA1wBgGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50\n",
        "k = 21\n",
        "d = 20\n",
        "T = 600\n",
        "assert(T<_datam.shape[1])\n",
        "S = _datam.shape[1]-T\n",
        "\n",
        "dh = Data_Handler(n,k,d,T,S,_datam)"
      ],
      "metadata": {
        "id": "T4GWC8eCBnW8"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter_u_a_1 = 100\n",
        "learning_rate_u_a_1 = 1e-2\n",
        "weight_R_u_a_1 = 0.3\n",
        "weight_L_u_a_1 = 0.3\n",
        "weight_O_u_a_1 = 0.3\n",
        "alpha_u_a_1 = (iter_u_a_1,learning_rate_u_a_1,weight_R_u_a_1,weight_L_u_a_1,weight_O_u_a_1)\n",
        "u_a_1 = U_A_Method_1(alpha_u_a_1,dh)"
      ],
      "metadata": {
        "id": "a_Wkfj2kC8-w"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiments on method 1"
      ],
      "metadata": {
        "id": "-tcGLRh2GBGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_u_beta_1 = 100\n",
        "learning_rate_u_beta_1 = 1e-2\n",
        "weight_R_u_beta_1 = 0.5\n",
        "weight_L_u_beta_1 = 0.5\n",
        "phi_1 = (iter_u_beta_1,learning_rate_u_beta_1, weight_R_u_beta_1, weight_L_u_beta_1)\n",
        "u_beta_1 = U_beta_Method_1(phi_1,dh)\n",
        "\n",
        "opi_1 = OPI(dh,u_beta_1,u_a_1)\n",
        "logger_name = opi_1.get_string() +'-'+dh.get_string()\n",
        "logger_opi_1 = Logger(logger_name,dh)"
      ],
      "metadata": {
        "id": "nbqPUb3tFmn0"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRUsC5_QOiB2",
        "outputId": "47391180-ebf2-47e3-e6f2-4651fa6b1543"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.9372352650771337e-27"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  opi_1 = OPI(dh,u_beta_1,u_a_1)\n",
        "  logger_name =  opi_1.get_string() +'-['+str(i)+']-'+dh.get_string()\n",
        "  logger_opi_1 = Logger(logger_name,dh)\n",
        "  beta, A = opi_1.run(1000,logger_opi_1)\n",
        "  logger_opi_1.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZuyVywzGDxk",
        "outputId": "7347fd29-5f31-41e8-c73e-1f1fa5ceaeab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:20<00:00, 12.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[0]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:15<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[1]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:22<00:00, 12.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[2]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:05<00:00, 15.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[3]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:18<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[4]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:11<00:00, 13.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[5]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:24<00:00, 11.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[6]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:09<00:00, 14.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[7]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:15<00:00, 13.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[8]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 1000/1000 [01:28<00:00, 11.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " opi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-[9]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VYVhKq8ZbHHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_opi_1.plot_scatter_LR()"
      ],
      "metadata": {
        "id": "k52kTRqkOoFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_opi_1.dist_plot()"
      ],
      "metadata": {
        "id": "PfZRbUWlO6GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiments on method 2"
      ],
      "metadata": {
        "id": "egFyivbQPrhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_u_beta_2 = 100\n",
        "learning_rate_u_beta_2 = 1e-2\n",
        "weight_R_u_beta_2 = 0.5\n",
        "weight_L_u_beta_2 = 0.5\n",
        "weight_reg_u_beta_2 = 0.5\n",
        "phi_2 = (iter_u_beta_2,learning_rate_u_beta_2, weight_R_u_beta_2, weight_L_u_beta_2,weight_reg_u_beta_2)\n",
        "u_beta_2 = U_beta_Method_2(phi_2,dh)\n",
        "\n",
        "opi_2 = OPI(dh,u_beta_2,u_a_1)\n",
        "logger_name = opi_2.get_string() +'-'+dh.get_string()\n",
        "logger_opi_2 = Logger(logger_name,dh)"
      ],
      "metadata": {
        "id": "1NBW0iQyPsg0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, A = opi_2.run(100,logger_opi_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ohHltO8P74d",
        "outputId": "762bb3a5-993f-412f-970a-ebc156bddd4a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OPI Scheme: 100%|██████████| 100/100 [00:05<00:00, 18.74it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXyxVDSTQC6F",
        "outputId": "4fd8752b-ca4d-43ce-87f1-21b8cfd2c205"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.845526698138814e-28"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  opi_2 = OPI(dh,u_beta_2,u_a_1)\n",
        "  logger_name = opi_2.get_string()+'-['+str(i)+']-'+dh.get_string()\n",
        "  logger_opi_2 = Logger(logger_name,dh)\n",
        "  beta, A = opi_2.run(1000,logger_opi_2)\n",
        "  logger_opi_2.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "sHio-8Ccd-Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0Ftuxm4eSVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_opi_2.plot_scatter_LR()"
      ],
      "metadata": {
        "id": "Q2c-s-vtQC3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_opi_2.dist_plot()"
      ],
      "metadata": {
        "id": "6cyGPhzsQFTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DOI Method"
      ],
      "metadata": {
        "id": "3GI1DXNhBLYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "5NfSoGBMBqfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DOI:\n",
        "    def __init__(self, data_handler: Data_Handler, U_beta: U_beta_Method, U_A: U_A_Method, U_O: U_O_Method):\n",
        "        self.n = data_handler.n\n",
        "        self.k = data_handler.k\n",
        "        self.d = data_handler.d\n",
        "        self.T = data_handler.T\n",
        "        self.S = data_handler.S\n",
        "        self.data_handler = data_handler\n",
        "        self.U_beta = U_beta\n",
        "        self.U_A = U_A\n",
        "        self.U_O = U_O\n",
        "        pass\n",
        "\n",
        "    def get_string(self):\n",
        "        return f\"doi-{self.U_beta.get_string()}-{self.U_A.get_string()}-{self.U_O.get_string()}\"\n",
        "\n",
        "    def run(self, iter_max=100, logger:Logger=None, random_matrix_scale=2):\n",
        "        A = random_matrix((self.d, self.k),random_matrix_scale)\n",
        "        beta = self.data_handler.linear_l2_regression(A)\n",
        "        for iter in tqdm(range(iter_max), desc='DOI Scheme'):\n",
        "            A_new = A + self.U_A.get_delta_A(beta, A)\n",
        "            beta = beta + self.U_beta.get_delta_beta(beta, A, A_new)\n",
        "            A = A_new\n",
        "            if logger is not None:\n",
        "                logger.log_RLO(self.data_handler.compute_reward(beta,A),self.data_handler.compute_loss(beta,A), self.data_handler.compute_orthogonal_condition_normF(A))\n",
        "        beta, A = self.U_O.get_new_beta_A(beta, A)\n",
        "        return beta, A\n"
      ],
      "metadata": {
        "id": "F8cVBB3RBQg7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expriment"
      ],
      "metadata": {
        "id": "cwjFplP3CdOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50\n",
        "k = 21\n",
        "d = 20\n",
        "T = 600\n",
        "assert(T<_datam.shape[1])\n",
        "S = _datam.shape[1]-T\n",
        "\n",
        "dh = Data_Handler(n,k,d,T,S,_datam)"
      ],
      "metadata": {
        "id": "iUebQmi0SGKm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iter_u_a_1 = 100\n",
        "learning_rate_u_a_1 = 1e-2\n",
        "weight_R_u_a_1 = 0.3\n",
        "weight_L_u_a_1 = 0.3\n",
        "weight_O_u_a_1 = 0.3\n",
        "alpha_u_a_1 = (iter_u_a_1,learning_rate_u_a_1,weight_R_u_a_1,weight_L_u_a_1,weight_O_u_a_1)\n",
        "u_a_1 = U_A_Method_1(alpha_u_a_1,dh)\n",
        "\n",
        "iter_u_o_1 = 100\n",
        "learning_rate_A_u_o_1 = 1e-2\n",
        "learning_rate_beta_u_o_1 = 1e-2\n",
        "weight_reg_u_o_1 = 0.5\n",
        "lamb_u_o_1 = (iter_u_o_1, learning_rate_A_u_o_1, learning_rate_beta_u_o_1, weight_reg_u_o_1)\n",
        "u_o_1 = U_O_Method_1(lamb_u_o_1,dh)"
      ],
      "metadata": {
        "id": "Y2Bar26oSGID"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiments on method 1"
      ],
      "metadata": {
        "id": "8LnWQ6yZR_o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_u_beta_1 = 100\n",
        "learning_rate_u_beta_1 = 1e-2\n",
        "weight_R_u_beta_1 = 0.5\n",
        "weight_L_u_beta_1 = 0.5\n",
        "phi_1 = (iter_u_beta_1,learning_rate_u_beta_1, weight_R_u_beta_1, weight_L_u_beta_1)\n",
        "u_beta_1 = U_beta_Method_1(phi_1,dh)\n",
        "\n",
        "doi_1 = DOI(dh,u_beta_1,u_a_1,u_o_1)\n",
        "logger_name = doi_1.get_string() + '-'+dh.get_string()\n",
        "logger_doi_1 = Logger(logger_name,dh)"
      ],
      "metadata": {
        "id": "4x8KfkL3CgfL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, A = doi_1.run(100,logger_doi_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giN1TKP-T756",
        "outputId": "7f101b1c-9395-4b07-ecc9-50099f470d8a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 100/100 [00:03<00:00, 26.33it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:04<00:00, 22.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y65buLyeT727",
        "outputId": "1d1e34bc-37cf-4dd2-c4c3-c38d15b11e79"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0455176782715557e-28"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  doi_1 = DOI(dh,u_beta_1,u_a_1,u_o_1)\n",
        "  logger_name = doi_1.get_string() +'-['+str(i)+']-'+dh.get_string()\n",
        "  logger_doi_1 = Logger(logger_name,dh)\n",
        "  beta, A = doi_1.run(1000,logger_doi_1)\n",
        "  logger_doi_1.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iznIQuXrfMQ6",
        "outputId": "486fe014-2c65-490c-847c-23b86a0b7c60"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:44<00:00, 22.46it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:05<00:00, 19.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[0]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:43<00:00, 22.76it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:04<00:00, 22.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[1]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:44<00:00, 22.44it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:05<00:00, 18.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[2]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:44<00:00, 22.54it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:06<00:00, 16.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[3]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:43<00:00, 22.87it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:04<00:00, 22.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[4]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:41<00:00, 23.83it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:04<00:00, 22.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[5]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:44<00:00, 22.60it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:04<00:00, 21.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[6]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:44<00:00, 22.69it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:05<00:00, 19.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[7]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:44<00:00, 22.59it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:06<00:00, 16.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[8]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 1000/1000 [00:43<00:00, 23.07it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:06<00:00, 14.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " doi-U_beta[100,100,5000,5000]-U_A[100,100,3000,3000,3000]-U_O[100,100,100,5000]-[9]-50-21-20-600-155 : dumped ROL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FYu4viCzfq23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_doi_1.plot_scatter_LR()"
      ],
      "metadata": {
        "id": "TGFimqwKT8d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0kO6Do_T8aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Experiments on method 2\n"
      ],
      "metadata": {
        "id": "llh5SX11UI5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_u_beta_2 = 100\n",
        "learning_rate_u_beta_2 = 1e-2\n",
        "weight_R_u_beta_2 = 0.5\n",
        "weight_L_u_beta_2 = 0.5\n",
        "weight_reg_u_beta_2 = 0.5\n",
        "phi_2 = (iter_u_beta_2,learning_rate_u_beta_2, weight_R_u_beta_2, weight_L_u_beta_2,weight_reg_u_beta_2)\n",
        "u_beta_2 = U_beta_Method_2(phi_2,dh)\n",
        "\n",
        "doi_2 = DOI(dh,u_beta_2,u_a_1,u_o_1)\n",
        "logger_name = doi_2.get_string() +'-'+dh.get_string()\n",
        "logger_doi_2 = Logger(logger_name,dh)"
      ],
      "metadata": {
        "id": "bugWjusGUI5m"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, A = doi_2.run(100,logger_doi_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9LFymsJUI5m",
        "outputId": "82d3bc85-770e-4ca4-c73a-5903bf24cebb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOI Scheme: 100%|██████████| 100/100 [00:08<00:00, 11.23it/s]\n",
            "U_O_Method_1:get_new_beta_A: 100%|██████████| 100/100 [00:04<00:00, 21.85it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWpIv_RKUI5m",
        "outputId": "44d20d3f-f220-4312-e4af-ef4a6c2fda73"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.141694284061615e-28"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  doi_2 = DOI(dh,u_beta_2,u_a_1,u_o_1)\n",
        "  logger_name = doi_2.get_string() +'-['+str(i)+']-'+dh.get_string()\n",
        "  logger_doi_2 = Logger(logger_name,dh)\n",
        "  beta, A = doi_2.run(1000,logger_doi_2)\n",
        "  logger_doi_2.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "koBYYxMWfzwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKNxMHemfzlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_doi_2.plot_scatter_LR() "
      ],
      "metadata": {
        "id": "TfEZTShZUI5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6BrG2FNSBK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NO Preference Method"
      ],
      "metadata": {
        "id": "k3Ra6wLIBu0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "ln_RA744ByIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "class MO_NPM_1:\n",
        "    def __init__(self, data_handler: Data_Handler, learning_rate_A,learning_rate_beta):\n",
        "        self.n = data_handler.n\n",
        "        self.k = data_handler.k\n",
        "        self.d = data_handler.d\n",
        "        self.T = data_handler.T\n",
        "        self.S = data_handler.S\n",
        "        self.data_handler = data_handler\n",
        "        self.learning_rate_A = learning_rate_A\n",
        "        self.learning_rate_beta = learning_rate_beta\n",
        "        pass\n",
        "\n",
        "    def run(self, iter_max=100, logger:Logger=None):\n",
        "        A_i = random_matrix((self.d,self.k))\n",
        "        A_i = gram_schmidt_algorithm(A_i)\n",
        "        beta_i = self.data_handler.linear_l2_regression(A_i)\n",
        "        R_i = self.data_handler.compute_reward(beta_i, A_i)\n",
        "        L_i = self.data_handler.compute_loss(beta_i, A_i)\n",
        "        A_opt = A_i\n",
        "        beta_opt = beta_i\n",
        "        R_opt = R_i\n",
        "        L_opt = L_i\n",
        "        for iter in tqdm(range(iter_max), desc=\"MO_NPM_2\"):\n",
        "            R_grad_beta, R_grad_A = self.data_handler.compute_reward_gradient_beta_A(beta_i, A_i)\n",
        "            L_grad_beta, L_grad_A = self.data_handler.compute_loss_gradient_beta_A(beta_i, A_i)\n",
        "            O_grad_A = self.data_handler.compute_orthogonal_condition_normF_gradient_A(A_i)\n",
        "            deltaA = float(1-R_i)*R_grad_A - float(L_i)*L_grad_A - 0.5*O_grad_A\n",
        "            deltabeta = float(1-R_i)*R_grad_beta - float(L_i)*L_grad_beta\n",
        "            T_i =  0.5*self.learning_rate_A *(np.matmul(deltaA.T,A_i) - np.matmul(A_i.T,deltaA))\n",
        "            Q = cayley_transformation(T_i)\n",
        "            A_i = np.matmul(A_i, Q)\n",
        "            beta_i = beta_i + self.learning_rate_beta*deltabeta\n",
        "            R_i = self.data_handler.compute_reward(beta_i, A_i)\n",
        "            L_i = self.data_handler.compute_loss(beta_i, A_i)\n",
        "            if logger is not None:\n",
        "                logger.log_RLO(R_i,L_i,self.data_handler.compute_orthogonal_condition_normF(A_i))\n",
        "            if R_i > R_opt:\n",
        "                A_opt = A_i\n",
        "                beta_opt = beta_i\n",
        "                R_opt = R_i\n",
        "                L_opt = L_i\n",
        "        return beta_opt, A_opt\n",
        "\n",
        "    def get_string(self):\n",
        "        return f\"NPM1[{int(1000*self.learning_rate_A)}-{int(1000*self.learning_rate_beta)}]\"\n",
        "\n",
        "class MO_NPM_2:\n",
        "    def __init__(self, data_handler: Data_Handler,learning_rate_A, learning_rate_beta):\n",
        "        self.n = data_handler.n\n",
        "        self.k = data_handler.k\n",
        "        self.d = data_handler.d\n",
        "        self.T = data_handler.T\n",
        "        self.S = data_handler.S\n",
        "        self.data_handler = data_handler\n",
        "        self.learning_rate_A = learning_rate_A\n",
        "        self.learning_rate_beta = learning_rate_beta\n",
        "        pass\n",
        "\n",
        "    def run(self, iter_max=100, logger:Logger=None):\n",
        "        A_i = random_matrix((self.d,self.k))\n",
        "        A_i = gram_schmidt_algorithm(A_i)\n",
        "        beta_i = self.data_handler.linear_l2_regression(A_i)\n",
        "        R_i = self.data_handler.compute_reward(beta_i, A_i)\n",
        "        L_i = self.data_handler.compute_loss(beta_i, A_i)\n",
        "        A_opt = A_i\n",
        "        beta_opt = beta_i\n",
        "        R_opt = R_i\n",
        "        L_opt = L_i\n",
        "        for iter in tqdm(range(iter_max), desc=\"MO_NPM_2\"):\n",
        "            R_grad_beta, R_grad_A = self.data_handler.compute_reward_gradient_beta_A(beta_i, A_i)\n",
        "            L_grad_beta, L_grad_A = self.data_handler.compute_loss_gradient_beta_A(beta_i, A_i)\n",
        "            O_grad_A = self.data_handler.compute_orthogonal_condition_normF_gradient_A(A_i)\n",
        "            deltaA = float(1-R_i)*R_grad_A - float(L_i)*L_grad_A - 0.5*O_grad_A\n",
        "            deltabeta = float(1-R_i)*R_grad_beta - float(L_i)*L_grad_beta\n",
        "            A_i = A_i + self.learning_rate_A * deltaA\n",
        "            beta_i = beta_i + self.learning_rate_beta*deltabeta\n",
        "            R_i = self.data_handler.compute_reward(beta_i, A_i)\n",
        "            L_i = self.data_handler.compute_loss(beta_i, A_i)\n",
        "            if logger is not None:\n",
        "                logger.log_RLO(R_i,L_i,self.data_handler.compute_orthogonal_condition_normF(A_i))\n",
        "            if R_i > R_opt:\n",
        "                A_opt = A_i\n",
        "                beta_opt = beta_i\n",
        "                R_opt = R_i\n",
        "                L_opt = L_i\n",
        "        return beta_opt, A_opt\n",
        "        \n",
        "    def get_string(self):\n",
        "        return f\"NPM2[{int(1000*self.learning_rate_A)}-{int(1000*self.learning_rate_beta)}]\""
      ],
      "metadata": {
        "id": "tkZ98GNYBc8p"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Method 1"
      ],
      "metadata": {
        "id": "2WWGk72iB1CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50\n",
        "k = 21\n",
        "d = 20\n",
        "T = 600\n",
        "assert(T<_datam.shape[1])\n",
        "S = _datam.shape[1]-T\n",
        "\n",
        "dh = Data_Handler(n,k,d,T,S,_datam)"
      ],
      "metadata": {
        "id": "7gUv6B7VdMaw"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_A_monpm_1 = 1e-2\n",
        "learning_rate_beta_monpm_1 = 1e-2"
      ],
      "metadata": {
        "id": "L_c8LyFfB4Sw"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monpm_1 = MO_NPM_1(dh,learning_rate_A_monpm_1,learning_rate_beta_monpm_1)\n",
        "logger_name = monpm_1.get_string()+'-'+dh.get_string()\n",
        "logger_monpm_1 = Logger(logger_name,dh)"
      ],
      "metadata": {
        "id": "QYB-eYAOgwJC"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, A = monpm_1.run(iter_max=100,logger=logger_monpm_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuUKiWEWB7Bo",
        "outputId": "506afb8f-47ab-4f34-91a1-3b79755d5122"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MO_NPM_2: 100%|██████████| 100/100 [00:04<00:00, 21.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "id": "zEgE2Cnue_19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  monpm_1 = MO_NPM_1(dh,learning_rate_A_monpm_1,learning_rate_beta_monpm_1)\n",
        "  logger_name = monpm_1.get_string()+'-['+str(i)+']-'+dh.get_string()\n",
        "  logger_monpm_1 = Logger(logger_name, dh)\n",
        "  beta, A = monpm_1.run(iter_max=1000,logger=logger_monpm_1)\n",
        "  logger_monpm_1.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "uJDZxZ7CiN7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZeDLzm5iOX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_monpm_1.plot_scatter_LR() "
      ],
      "metadata": {
        "id": "jGNkGbK-duuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment Method 2"
      ],
      "metadata": {
        "id": "uZ2DimYXB4yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 50\n",
        "k = 21\n",
        "d = 20\n",
        "T = 600\n",
        "assert(T<_datam.shape[1])\n",
        "S = _datam.shape[1]-T\n",
        "\n",
        "dh = Data_Handler(n,k,d,T,S,_datam)"
      ],
      "metadata": {
        "id": "QdvHZsznfEV2"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_A_monpm_2 = 1e-2\n",
        "learning_rate_beta_monpm_2 = 1e-2"
      ],
      "metadata": {
        "id": "rqYmTZ9BfLXc"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monpm_2 = MO_NPM_2(dh,learning_rate_A_monpm_2,learning_rate_beta_monpm_2)\n",
        "logger_name = monpm_2.get_string()+'-'+dh.get_string()\n",
        "logger_monpm_2 = Logger(logger_name,dh)"
      ],
      "metadata": {
        "id": "IqtTM4dBi-bU"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, A = monpm_2.run(iter_max=100,logger=logger_monpm_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li1vg2ipfU6A",
        "outputId": "9c03ff39-b158-4e0d-ee06-2d5619b13b35"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "MO_NPM_2: 100%|██████████| 100/100 [00:03<00:00, 27.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh.compute_orthogonal_condition_normF(A)"
      ],
      "metadata": {
        "id": "kur-UajjfaM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  monpm_2 = MO_NPM_2(dh,learning_rate_A_monpm_2,learning_rate_beta_monpm_2)\n",
        "  logger_name = monpm_2.get_string()+'-['+str(i)+']-'+dh.get_string()\n",
        "  logger_monpm_2 = Logger(logger_name,dh)\n",
        "  beta, A = monpm_2.run(iter_max=1000,logger=logger_monpm_2)\n",
        "  logger_monpm_2.dump(RESULTS_FOLDER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAJ2ZCdKjQmU",
        "outputId": "55238adb-2ddd-4586-ebfa-f3c8d4a7274b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:38<00:00, 25.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[0]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:37<00:00, 26.67it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[1]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:40<00:00, 24.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[2]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:38<00:00, 25.88it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[3]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:37<00:00, 26.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[4]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:40<00:00, 24.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[5]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:38<00:00, 25.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[6]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:39<00:00, 25.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[7]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:38<00:00, 26.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[8]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "MO_NPM_2: 100%|██████████| 1000/1000 [00:38<00:00, 25.67it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " NPM2[10-10]-[9]-50-21-20-600-155 : dumped ROL\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXYacNG6jQct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger_monpm_2.plot_scatter_LR() "
      ],
      "metadata": {
        "id": "Y8MyyDsTfcUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emfAW0U9ffKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}